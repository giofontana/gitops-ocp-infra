apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    opendatahub.io/connection-path: qwen3-vl-8b-instruct-fp8
    opendatahub.io/connections: llm-models
    opendatahub.io/hardware-profile-name: default-profile-nvidia-gpu
    opendatahub.io/hardware-profile-namespace: redhat-ods-applications
    opendatahub.io/model-type: generative
    openshift.io/description: ""
    openshift.io/display-name: Qwen/Qwen3-VL-8B-Instruct-FP8
    security.opendatahub.io/enable-auth: "false"
    serving.kserve.io/deploymentMode: RawDeployment
    serving.kserve.io/stop: "false"
  creationTimestamp: "2025-12-22T19:59:39Z"
  finalizers:
  - inferenceservice.finalizers
  - odh.inferenceservice.finalizers
  generation: 3
  labels:
    networking.kserve.io/visibility: exposed
    opendatahub.io/dashboard: "true"
  name: qwenqwen3-vl-8b-instruct-fp8
  namespace: llm-models
  resourceVersion: "179834894"
  uid: 51a14ff5-81c7-4f4d-8949-adbdf1da666f
spec:
  predictor:
    automountServiceAccountToken: false
    maxReplicas: 1
    minReplicas: 1
    model:
      args:
      - --max-model-len=30000
      - --served-model-name=Qwen/Qwen3-VL-8B-Instruct-FP8
      - --enable-auto-tool-choice
      - --tool-call-parser=llama3_json
      modelFormat:
        name: vLLM
      name: ""
      resources:
        limits:
          cpu: "2"
          memory: 4Gi
          nvidia.com/gpu: "1"
        requests:
          cpu: "2"
          memory: 4Gi
          nvidia.com/gpu: "1"
      runtime: qwenqwen3-vl-8b-instruct-fp8
      storage:
        key: llm-models
        path: qwen3-vl-8b-instruct-fp8
    nodeSelector:
      gpu: "true"
    serviceAccountName: llm-models-sa
status:
  address:
    url: http://qwenqwen3-vl-8b-instruct-fp8-predictor.llm-models.svc.cluster.local
  components:
    predictor: {}
  conditions:
  - lastTransitionTime: "2026-01-15T00:33:14Z"
    status: "True"
    type: IngressReady
  - lastTransitionTime: "2026-02-09T18:59:32Z"
    status: "True"
    type: PredictorReady
  - lastTransitionTime: "2026-02-09T18:59:32Z"
    status: "True"
    type: Ready
  - lastTransitionTime: "2026-01-15T00:33:14Z"
    severity: Info
    status: "False"
    type: Stopped
  deploymentMode: RawDeployment
  modelStatus:
    copies:
      failedCopies: 0
      totalCopies: 1
    lastFailureInfo:
      exitCode: 1
      reason: ModelLoadFailed
    states:
      activeModelState: Loaded
      targetModelState: Loaded
    transitionStatus: UpToDate
  observedGeneration: 1
  servingRuntimeName: qwenqwen3-vl-8b-instruct-fp8
  url: https://qwenqwen3-vl-8b-instruct-fp8-llm-models.apps.simpsons.lab.gfontana.me